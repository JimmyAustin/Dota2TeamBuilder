[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 12970645487718151018
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 9792811828
locality {
  bus_id: 1
  links {
  }
}
incarnation: 316511198629048629
physical_device_desc: "device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1"
]
Failed to import show image
No module named 'tkinter'
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [1000],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 1000)              211000    
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 1001      
=================================================================
Total params: 212,001
Trainable params: 212,001
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 210

Epoch 00001: val_loss improved from inf to 54.40095, saving model to ./tmp/classification__CRPHSVZZUW__.01-54.40.hdf5
Epcoh: 0, Value: 0.470625

Epoch 00002: val_loss improved from 54.40095 to 53.79491, saving model to ./tmp/classification__CRPHSVZZUW__.02-53.79.hdf5
Epcoh: 1, Value: 0.453125

Epoch 00003: val_loss improved from 53.79491 to 53.63484, saving model to ./tmp/classification__CRPHSVZZUW__.03-53.63.hdf5
Epcoh: 2, Value: 0.465

Epoch 00004: val_loss did not improve from 53.63484
Epcoh: 3, Value: 0.4525

Epoch 00005: val_loss did not improve from 53.63484
Epcoh: 4, Value: 0.445

Epoch 00006: val_loss did not improve from 53.63484
Epcoh: 5, Value: 0.465

Epoch 00007: val_loss did not improve from 53.63484
Epcoh: 6, Value: 0.42875

Epoch 00008: val_loss did not improve from 53.63484
Epcoh: 7, Value: 0.464375
end training
loaded from validating_generator
0.465625
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [1000, 500],
 'loss_function': 'mean_squared_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [1000, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 1000)              241000    
_________________________________________________________________
dense_4 (Dense)              (None, 500)               500500    
_________________________________________________________________
dense_5 (Dense)              (None, 2)                 1002      
=================================================================
Total params: 742,502
Trainable params: 742,502
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 240

Epoch 00001: val_loss improved from inf to 0.23515, saving model to ./tmp/classification__EDFJ2NIHLW__.01-0.24.hdf5
Epcoh: 0, Value: 0.60375

Epoch 00002: val_loss did not improve from 0.23515
Epcoh: 1, Value: 0.60625

Epoch 00003: val_loss did not improve from 0.23515
Epcoh: 2, Value: 0.615

Epoch 00004: val_loss did not improve from 0.23515
Epcoh: 3, Value: 0.56875

Epoch 00005: val_loss did not improve from 0.23515
Epcoh: 4, Value: 0.595

Epoch 00006: val_loss did not improve from 0.23515
Epcoh: 5, Value: 0.559375
end training
loaded from validating_generator
0.5646875
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 1500, 1000],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 1500, 1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 2000)              2262000   
_________________________________________________________________
dense_7 (Dense)              (None, 1500)              3001500   
_________________________________________________________________
dense_8 (Dense)              (None, 1000)              1501000   
_________________________________________________________________
dense_9 (Dense)              (None, 2)                 2002      
=================================================================
Total params: 6,766,502
Trainable params: 6,766,502
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 1130

Epoch 00001: val_loss improved from inf to 233585284.76008, saving model to ./tmp/classification__WG05EF3H0Q__.01-233585284.76.hdf5
Epcoh: 0, Value: 0.52125

Epoch 00002: val_loss improved from 233585284.76008 to 233175415.83109, saving model to ./tmp/classification__WG05EF3H0Q__.02-233175415.83.hdf5
Epcoh: 1, Value: 0.526875

Epoch 00003: val_loss did not improve from 233175415.83109
Epcoh: 2, Value: 0.529375

Epoch 00004: val_loss did not improve from 233175415.83109
Epcoh: 3, Value: 0.510625

Epoch 00005: val_loss improved from 233175415.83109 to 232385668.25336, saving model to ./tmp/classification__WG05EF3H0Q__.05-232385668.25.hdf5
Epcoh: 4, Value: 0.525625

Epoch 00006: val_loss did not improve from 232385668.25336
Epcoh: 5, Value: 0.524375

Epoch 00007: val_loss did not improve from 232385668.25336
Epcoh: 6, Value: 0.520625

Epoch 00008: val_loss did not improve from 232385668.25336
Epcoh: 7, Value: 0.5475

Epoch 00009: val_loss did not improve from 232385668.25336
Epcoh: 8, Value: 0.551875

Epoch 00010: val_loss did not improve from 232385668.25336
Epcoh: 9, Value: 0.528125
end training
loaded from validating_generator
0.52875
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [2000, 1500, 200],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 1500, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (None, 2000)              1542000   
_________________________________________________________________
dense_11 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_12 (Dense)             (None, 200)               300200    
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 201       
=================================================================
Total params: 4,843,901
Trainable params: 4,843,901
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 770

Epoch 00001: val_loss improved from inf to 0.23677, saving model to ./tmp/classification__R8MGTMJGET__.01-0.24.hdf5
Epcoh: 0, Value: 0.57875

Epoch 00002: val_loss improved from 0.23677 to 0.23568, saving model to ./tmp/classification__R8MGTMJGET__.02-0.24.hdf5
Epcoh: 1, Value: 0.57625

Epoch 00003: val_loss did not improve from 0.23568
Epcoh: 2, Value: 0.605

Epoch 00004: val_loss did not improve from 0.23568
Epcoh: 3, Value: 0.6175

Epoch 00005: val_loss did not improve from 0.23568
Epcoh: 4, Value: 0.6

Epoch 00006: val_loss did not improve from 0.23568
Epcoh: 5, Value: 0.600625

Epoch 00007: val_loss did not improve from 0.23568
Epcoh: 6, Value: 0.58875
end training
loaded from validating_generator
0.588125
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 500],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adadelta'}
TESTING
LAYERS: [2000, 500]
EPOCHS: 20
--------ERROR--------

---------------------
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [1000, 100],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adamax'}
TESTING
LAYERS: [1000, 100]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_15 (Dense)             (None, 1000)              1131000   
_________________________________________________________________
dense_16 (Dense)             (None, 100)               100100    
_________________________________________________________________
dense_17 (Dense)             (None, 2)                 202       
=================================================================
Total params: 1,231,302
Trainable params: 1,231,302
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 1130

Epoch 00001: val_loss improved from inf to 211445526.16251, saving model to ./tmp/classification__RXPJ9TE2L1__.01-211445526.16.hdf5
Epcoh: 0, Value: 0.6

Epoch 00002: val_loss improved from 211445526.16251 to 210459940.58605, saving model to ./tmp/classification__RXPJ9TE2L1__.02-210459940.59.hdf5
Epcoh: 1, Value: 0.575

Epoch 00003: val_loss improved from 210459940.58605 to 207934927.52911, saving model to ./tmp/classification__RXPJ9TE2L1__.03-207934927.53.hdf5
Epcoh: 2, Value: 0.586875

Epoch 00004: val_loss did not improve from 207934927.52911
Epcoh: 3, Value: 0.5975

Epoch 00005: val_loss did not improve from 207934927.52911
Epcoh: 4, Value: 0.579375

Epoch 00006: val_loss did not improve from 207934927.52911
Epcoh: 5, Value: 0.595

Epoch 00007: val_loss did not improve from 207934927.52911
Epcoh: 6, Value: 0.57375

Epoch 00008: val_loss did not improve from 207934927.52911
Epcoh: 7, Value: 0.5825
end training
loaded from validating_generator
0.5809375
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [2000, 1500, 500],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adadelta'}
TESTING
LAYERS: [2000, 1500, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_18 (Dense)             (None, 2000)              1542000   
_________________________________________________________________
dense_19 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_20 (Dense)             (None, 500)               750500    
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 501       
=================================================================
Total params: 5,294,501
Trainable params: 5,294,501
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 770

Epoch 00001: val_loss improved from inf to 0.23661, saving model to ./tmp/classification__OZHV6XCBHY__.01-0.24.hdf5
Epcoh: 0, Value: 0.599375

Epoch 00002: val_loss did not improve from 0.23661
Epcoh: 1, Value: 0.61375

Epoch 00003: val_loss did not improve from 0.23661
Epcoh: 2, Value: 0.625

Epoch 00004: val_loss did not improve from 0.23661
Epcoh: 3, Value: 0.5875

Epoch 00005: val_loss did not improve from 0.23661
Epcoh: 4, Value: 0.59125

Epoch 00006: val_loss did not improve from 0.23661
Epcoh: 5, Value: 0.616875
end training
loaded from validating_generator
0.5634375
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 100],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adamax'}
TESTING
LAYERS: [2000, 100]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 2000)              1962000   
_________________________________________________________________
dense_23 (Dense)             (None, 100)               200100    
_________________________________________________________________
dense_24 (Dense)             (None, 2)                 202       
=================================================================
Total params: 2,162,302
Trainable params: 2,162,302
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 980

Epoch 00001: val_loss improved from inf to 233285380.87780, saving model to ./tmp/classification__1X4SVZWKM3__.01-233285380.88.hdf5
Epcoh: 0, Value: 0.544375

Epoch 00002: val_loss did not improve from 233285380.87780
Epcoh: 1, Value: 0.538125

Epoch 00003: val_loss improved from 233285380.87780 to 212892932.27639, saving model to ./tmp/classification__1X4SVZWKM3__.03-212892932.28.hdf5
Epcoh: 2, Value: 0.559375

Epoch 00004: val_loss did not improve from 212892932.27639
Epcoh: 3, Value: 0.56375

Epoch 00005: val_loss did not improve from 212892932.27639
Epcoh: 4, Value: 0.566875

Epoch 00006: val_loss did not improve from 212892932.27639
Epcoh: 5, Value: 0.564375

Epoch 00007: val_loss did not improve from 212892932.27639
Epcoh: 6, Value: 0.579375

Epoch 00008: val_loss did not improve from 212892932.27639
Epcoh: 7, Value: 0.585625
end training
loaded from validating_generator
0.5709375
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [1000, 100],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adagrad'}
TESTING
LAYERS: [1000, 100]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_25 (Dense)             (None, 1000)              861000    
_________________________________________________________________
dense_26 (Dense)             (None, 100)               100100    
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 101       
=================================================================
Total params: 961,201
Trainable params: 961,201
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 860

Epoch 00001: val_loss improved from inf to 0.23455, saving model to ./tmp/classification__ZH9AQHOPJE__.01-0.23.hdf5
Epcoh: 0, Value: 0.608125

Epoch 00002: val_loss did not improve from 0.23455
Epcoh: 1, Value: 0.59125

Epoch 00003: val_loss did not improve from 0.23455
Epcoh: 2, Value: 0.5825

Epoch 00004: val_loss did not improve from 0.23455
Epcoh: 3, Value: 0.60625

Epoch 00005: val_loss did not improve from 0.23455
Epcoh: 4, Value: 0.5875

Epoch 00006: val_loss did not improve from 0.23455
Epcoh: 5, Value: 0.59375
end training
loaded from validating_generator
0.5934375
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 1500, 1000],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adadelta'}
TESTING
LAYERS: [2000, 1500, 1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_28 (Dense)             (None, 2000)              2202000   
_________________________________________________________________
dense_29 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_30 (Dense)             (None, 1000)              1501000   
_________________________________________________________________
dense_31 (Dense)             (None, 2)                 2002      
=================================================================
Total params: 6,706,502
Trainable params: 6,706,502
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 1100

Epoch 00001: val_loss improved from inf to 236124472.52719, saving model to ./tmp/classification__3BEHEUY0GX__.01-236124472.53.hdf5
Epcoh: 0, Value: 0.534375

Epoch 00002: val_loss did not improve from 236124472.52719
Epcoh: 1, Value: 0.509375

Epoch 00003: val_loss improved from 236124472.52719 to 235494674.02175, saving model to ./tmp/classification__3BEHEUY0GX__.03-235494674.02.hdf5
Epcoh: 2, Value: 0.539375

Epoch 00004: val_loss improved from 235494674.02175 to 234514987.21945, saving model to ./tmp/classification__3BEHEUY0GX__.04-234514987.22.hdf5
Epcoh: 3, Value: 0.54125

Epoch 00005: val_loss did not improve from 234514987.21945
Epcoh: 4, Value: 0.519375

Epoch 00006: val_loss did not improve from 234514987.21945
Epcoh: 5, Value: 0.54125

Epoch 00007: val_loss improved from 234514987.21945 to 234494993.85285, saving model to ./tmp/classification__3BEHEUY0GX__.07-234494993.85.hdf5
Epcoh: 6, Value: 0.52

Epoch 00008: val_loss did not improve from 234494993.85285
Epcoh: 7, Value: 0.535

Epoch 00009: val_loss did not improve from 234494993.85285
Epcoh: 8, Value: 0.518125

Epoch 00010: val_loss did not improve from 234494993.85285
Epcoh: 9, Value: 0.535

Epoch 00011: val_loss did not improve from 234494993.85285
Epcoh: 10, Value: 0.505

Epoch 00012: val_loss did not improve from 234494993.85285
Epcoh: 11, Value: 0.53625
end training
loaded from validating_generator
0.5425
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 1500, 200],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adagrad'}
TESTING
LAYERS: [2000, 1500, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_32 (Dense)             (None, 2000)              242000    
_________________________________________________________________
dense_33 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_34 (Dense)             (None, 200)               300200    
_________________________________________________________________
dense_35 (Dense)             (None, 2)                 402       
=================================================================
Total params: 3,544,102
Trainable params: 3,544,102
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 120

Epoch 00001: val_loss improved from inf to 0.46453, saving model to ./tmp/classification__1RS6DOCVEJ__.01-0.46.hdf5
Epcoh: 0, Value: 0.538125

Epoch 00002: val_loss did not improve from 0.46453
Epcoh: 1, Value: 0.55125

Epoch 00003: val_loss improved from 0.46453 to 0.46425, saving model to ./tmp/classification__1RS6DOCVEJ__.03-0.46.hdf5
Epcoh: 2, Value: 0.5275

Epoch 00004: val_loss did not improve from 0.46425
Epcoh: 3, Value: 0.539375

Epoch 00005: val_loss improved from 0.46425 to 0.23617, saving model to ./tmp/classification__1RS6DOCVEJ__.05-0.24.hdf5
Epcoh: 4, Value: 0.590625

Epoch 00006: val_loss did not improve from 0.23617
Epcoh: 5, Value: 0.609375

Epoch 00007: val_loss did not improve from 0.23617
Epcoh: 6, Value: 0.5525

Epoch 00008: val_loss did not improve from 0.23617
Epcoh: 7, Value: 0.561875

Epoch 00009: val_loss did not improve from 0.23617
Epcoh: 8, Value: 0.53875

Epoch 00010: val_loss did not improve from 0.23617
Epcoh: 9, Value: 0.551875
end training
loaded from validating_generator
0.5421875
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [200],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adadelta'}
TESTING
LAYERS: [200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_36 (Dense)             (None, 200)               196200    
_________________________________________________________________
dense_37 (Dense)             (None, 1)                 201       
=================================================================
Total params: 196,401
Trainable params: 196,401
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 980

Epoch 00001: val_loss improved from inf to 0.23628, saving model to ./tmp/classification__QOC0MI02GM__.01-0.24.hdf5
Epcoh: 0, Value: 0.593125

Epoch 00002: val_loss did not improve from 0.23628
Epcoh: 1, Value: 0.586875

Epoch 00003: val_loss did not improve from 0.23628
Epcoh: 2, Value: 0.6075

Epoch 00004: val_loss did not improve from 0.23628
Epcoh: 3, Value: 0.595625

Epoch 00005: val_loss did not improve from 0.23628
Epcoh: 4, Value: 0.59

Epoch 00006: val_loss did not improve from 0.23628
Epcoh: 5, Value: 0.58125
end training
loaded from validating_generator
0.59375
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [1000, 200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [1000, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_38 (Dense)             (None, 1000)              891000    
_________________________________________________________________
dense_39 (Dense)             (None, 200)               200200    
_________________________________________________________________
dense_40 (Dense)             (None, 1)                 201       
=================================================================
Total params: 1,091,401
Trainable params: 1,091,401
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 890

Epoch 00001: val_loss improved from inf to 53.76280, saving model to ./tmp/classification__27VUDRO85S__.01-53.76.hdf5
Epcoh: 0, Value: 0.466875

Epoch 00002: val_loss improved from 53.76280 to 53.55286, saving model to ./tmp/classification__27VUDRO85S__.02-53.55.hdf5
Epcoh: 1, Value: 0.44375

Epoch 00003: val_loss did not improve from 53.55286
Epcoh: 2, Value: 0.454375

Epoch 00004: val_loss improved from 53.55286 to 53.52487, saving model to ./tmp/classification__27VUDRO85S__.04-53.52.hdf5
Epcoh: 3, Value: 0.479375

Epoch 00005: val_loss did not improve from 53.52487
Epcoh: 4, Value: 0.455

Epoch 00006: val_loss did not improve from 53.52487
Epcoh: 5, Value: 0.459375

Epoch 00007: val_loss did not improve from 53.52487
Epcoh: 6, Value: 0.4725

Epoch 00008: val_loss did not improve from 53.52487
Epcoh: 7, Value: 0.488125

Epoch 00009: val_loss did not improve from 53.52487
Epcoh: 8, Value: 0.476875
end training
loaded from validating_generator
0.4596875
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 1500, 500],
 'loss_function': 'mean_squared_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [2000, 1500, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_41 (Dense)             (None, 2000)              722000    
_________________________________________________________________
dense_42 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_43 (Dense)             (None, 500)               750500    
_________________________________________________________________
dense_44 (Dense)             (None, 2)                 1002      
=================================================================
Total params: 4,475,002
Trainable params: 4,475,002
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 360

Epoch 00001: val_loss improved from inf to 0.23585, saving model to ./tmp/classification__92JMF4O4Y1__.01-0.24.hdf5
Epcoh: 0, Value: 0.6

Epoch 00002: val_loss improved from 0.23585 to 0.23488, saving model to ./tmp/classification__92JMF4O4Y1__.02-0.23.hdf5
Epcoh: 1, Value: 0.608125

Epoch 00003: val_loss did not improve from 0.23488
Epcoh: 2, Value: 0.57375

Epoch 00004: val_loss did not improve from 0.23488
Epcoh: 3, Value: 0.59

Epoch 00005: val_loss did not improve from 0.23488
Epcoh: 4, Value: 0.551875

Epoch 00006: val_loss did not improve from 0.23488
Epcoh: 5, Value: 0.53375

Epoch 00007: val_loss did not improve from 0.23488
Epcoh: 6, Value: 0.53625
end training
loaded from validating_generator
0.554375
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [1000, 500],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [1000, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_45 (Dense)             (None, 1000)              981000    
_________________________________________________________________
dense_46 (Dense)             (None, 500)               500500    
_________________________________________________________________
dense_47 (Dense)             (None, 2)                 1002      
=================================================================
Total params: 1,482,502
Trainable params: 1,482,502
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 980

Epoch 00001: val_loss improved from inf to 0.23520, saving model to ./tmp/classification__4TK62O0X75__.01-0.24.hdf5
Epcoh: 0, Value: 0.6

Epoch 00002: val_loss improved from 0.23520 to 0.23470, saving model to ./tmp/classification__4TK62O0X75__.02-0.23.hdf5
Epcoh: 1, Value: 0.601875

Epoch 00003: val_loss did not improve from 0.23470
Epcoh: 2, Value: 0.598125

Epoch 00004: val_loss did not improve from 0.23470
Epcoh: 3, Value: 0.61875

Epoch 00005: val_loss did not improve from 0.23470
Epcoh: 4, Value: 0.590625

Epoch 00006: val_loss did not improve from 0.23470
Epcoh: 5, Value: 0.596875

Epoch 00007: val_loss did not improve from 0.23470
Epcoh: 6, Value: 0.585625
end training
loaded from validating_generator
0.58875
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 1000],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_48 (Dense)             (None, 2000)              2202000   
_________________________________________________________________
dense_49 (Dense)             (None, 1000)              2001000   
_________________________________________________________________
dense_50 (Dense)             (None, 2)                 2002      
=================================================================
Total params: 4,205,002
Trainable params: 4,205,002
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 1100

Epoch 00001: val_loss improved from inf to 233475320.26104, saving model to ./tmp/classification__NTV67JELXP__.01-233475320.26.hdf5
Epcoh: 0, Value: 0.54625

Epoch 00002: val_loss improved from 233475320.26104 to 233305374.05502, saving model to ./tmp/classification__NTV67JELXP__.02-233305374.06.hdf5
Epcoh: 1, Value: 0.55375

Epoch 00003: val_loss did not improve from 233305374.05502
Epcoh: 2, Value: 0.545625

Epoch 00004: val_loss did not improve from 233305374.05502
Epcoh: 3, Value: 0.5475

Epoch 00005: val_loss improved from 233305374.05502 to 232335684.35573, saving model to ./tmp/classification__NTV67JELXP__.05-232335684.36.hdf5
Epcoh: 4, Value: 0.5375

Epoch 00006: val_loss did not improve from 232335684.35573
Epcoh: 5, Value: 0.535625

Epoch 00007: val_loss did not improve from 232335684.35573
Epcoh: 6, Value: 0.525625

Epoch 00008: val_loss did not improve from 232335684.35573
Epcoh: 7, Value: 0.53125

Epoch 00009: val_loss did not improve from 232335684.35573
Epcoh: 8, Value: 0.530625

Epoch 00010: val_loss did not improve from 232335684.35573
Epcoh: 9, Value: 0.53875
end training
loaded from validating_generator
0.5315625
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 100],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 100]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_51 (Dense)             (None, 2000)              662000    
_________________________________________________________________
dense_52 (Dense)             (None, 100)               200100    
_________________________________________________________________
dense_53 (Dense)             (None, 2)                 202       
=================================================================
Total params: 862,302
Trainable params: 862,302
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 330

Epoch 00001: val_loss improved from inf to 0.23344, saving model to ./tmp/classification__IHY56N7HOV__.01-0.23.hdf5
Epcoh: 0, Value: 0.621875

Epoch 00002: val_loss did not improve from 0.23344
Epcoh: 1, Value: 0.61875

Epoch 00003: val_loss did not improve from 0.23344
Epcoh: 2, Value: 0.589375

Epoch 00004: val_loss did not improve from 0.23344
Epcoh: 3, Value: 0.56875

Epoch 00005: val_loss did not improve from 0.23344
Epcoh: 4, Value: 0.5525

Epoch 00006: val_loss did not improve from 0.23344
Epcoh: 5, Value: 0.554375
end training
loaded from validating_generator
0.5646875
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 500],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_54 (Dense)             (None, 2000)              662000    
_________________________________________________________________
dense_55 (Dense)             (None, 500)               1000500   
_________________________________________________________________
dense_56 (Dense)             (None, 2)                 1002      
=================================================================
Total params: 1,663,502
Trainable params: 1,663,502
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 330

Epoch 00001: val_loss improved from inf to 0.23346, saving model to ./tmp/classification__6H681QPSA0__.01-0.23.hdf5
Epcoh: 0, Value: 0.62625

Epoch 00002: val_loss did not improve from 0.23346
Epcoh: 1, Value: 0.62375

Epoch 00003: val_loss did not improve from 0.23346
Epcoh: 2, Value: 0.58375

Epoch 00004: val_loss did not improve from 0.23346
Epcoh: 3, Value: 0.564375

Epoch 00005: val_loss did not improve from 0.23346
Epcoh: 4, Value: 0.565

Epoch 00006: val_loss did not improve from 0.23346
Epcoh: 5, Value: 0.556875
end training
loaded from validating_generator
0.55625
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 200],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_57 (Dense)             (None, 2000)              422000    
_________________________________________________________________
dense_58 (Dense)             (None, 200)               400200    
_________________________________________________________________
dense_59 (Dense)             (None, 2)                 402       
=================================================================
Total params: 822,602
Trainable params: 822,602
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 210

Epoch 00001: val_loss improved from inf to 0.23225, saving model to ./tmp/classification__SC4OZ80WWG__.01-0.23.hdf5
Epcoh: 0, Value: 0.599375

Epoch 00002: val_loss did not improve from 0.23225
Epcoh: 1, Value: 0.616875

Epoch 00003: val_loss did not improve from 0.23225
Epcoh: 2, Value: 0.59625

Epoch 00004: val_loss did not improve from 0.23225
Epcoh: 3, Value: 0.593125

Epoch 00005: val_loss did not improve from 0.23225
Epcoh: 4, Value: 0.5875

Epoch 00006: val_loss did not improve from 0.23225
Epcoh: 5, Value: 0.600625
end training
loaded from validating_generator
0.58625
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [2000, 1000],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_60 (Dense)             (None, 2000)              2202000   
_________________________________________________________________
dense_61 (Dense)             (None, 1000)              2001000   
_________________________________________________________________
dense_62 (Dense)             (None, 2)                 2002      
=================================================================
Total params: 4,205,002
Trainable params: 4,205,002
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 1100

Epoch 00001: val_loss improved from inf to 267244518.83813, saving model to ./tmp/classification__E5K7MVMNHD__.01-267244518.84.hdf5
Epcoh: 0, Value: 0.47875

Epoch 00002: val_loss did not improve from 267244518.83813
Epcoh: 1, Value: 0.474375

Epoch 00003: val_loss did not improve from 267244518.83813
Epcoh: 2, Value: 0.489375

Epoch 00004: val_loss did not improve from 267244518.83813
Epcoh: 3, Value: 0.46375

Epoch 00005: val_loss did not improve from 267244518.83813
Epcoh: 4, Value: 0.47625

Epoch 00006: val_loss improved from 267244518.83813 to 266414784.46065, saving model to ./tmp/classification__E5K7MVMNHD__.06-266414784.46.hdf5
Epcoh: 5, Value: 0.445625

Epoch 00007: val_loss did not improve from 266414784.46065
Epcoh: 6, Value: 0.464375

Epoch 00008: val_loss did not improve from 266414784.46065
Epcoh: 7, Value: 0.46

Epoch 00009: val_loss did not improve from 266414784.46065
Epcoh: 8, Value: 0.465

Epoch 00010: val_loss did not improve from 266414784.46065
Epcoh: 9, Value: 0.455

Epoch 00011: val_loss did not improve from 266414784.46065
Epcoh: 10, Value: 0.458125
end training
loaded from validating_generator
0.475625
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [2000, 500],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_63 (Dense)             (None, 2000)              422000    
_________________________________________________________________
dense_64 (Dense)             (None, 500)               1000500   
_________________________________________________________________
dense_65 (Dense)             (None, 1)                 501       
=================================================================
Total params: 1,423,001
Trainable params: 1,423,001
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 210

Epoch 00001: val_loss improved from inf to 0.23280, saving model to ./tmp/classification__GW62IK0IV7__.01-0.23.hdf5
Epcoh: 0, Value: 0.595625

Epoch 00002: val_loss did not improve from 0.23280
Epcoh: 1, Value: 0.590625

Epoch 00003: val_loss did not improve from 0.23280
Epcoh: 2, Value: 0.611875

Epoch 00004: val_loss did not improve from 0.23280
Epcoh: 3, Value: 0.60875

Epoch 00005: val_loss did not improve from 0.23280
Epcoh: 4, Value: 0.61125

Epoch 00006: val_loss did not improve from 0.23280
Epcoh: 5, Value: 0.559375
end training
loaded from validating_generator
0.5596875
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adamax'}
TESTING
LAYERS: [2000, 200]
EPOCHS: 20
--------ERROR--------

---------------------
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 1,
 'layers': [1000, 200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adagrad'}
TESTING
LAYERS: [1000, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_67 (Dense)             (None, 1000)              331000    
_________________________________________________________________
dense_68 (Dense)             (None, 200)               200200    
_________________________________________________________________
dense_69 (Dense)             (None, 1)                 201       
=================================================================
Total params: 531,401
Trainable params: 531,401
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 330

Epoch 00001: val_loss improved from inf to 54.03198, saving model to ./tmp/classification__7QP58PHQC8__.01-54.03.hdf5
Epcoh: 0, Value: 0.470625

Epoch 00002: val_loss improved from 54.03198 to 53.66430, saving model to ./tmp/classification__7QP58PHQC8__.02-53.66.hdf5
Epcoh: 1, Value: 0.465

Epoch 00003: val_loss did not improve from 53.66430
Epcoh: 2, Value: 0.47375

Epoch 00004: val_loss did not improve from 53.66430
Epcoh: 3, Value: 0.469375

Epoch 00005: val_loss improved from 53.66430 to 53.36984, saving model to ./tmp/classification__7QP58PHQC8__.05-53.37.hdf5
Epcoh: 4, Value: 0.465625

Epoch 00006: val_loss did not improve from 53.36984
Epcoh: 5, Value: 0.47625

Epoch 00007: val_loss did not improve from 53.36984
Epcoh: 6, Value: 0.465

Epoch 00008: val_loss did not improve from 53.36984
Epcoh: 7, Value: 0.460625

Epoch 00009: val_loss improved from 53.36984 to 53.32041, saving model to ./tmp/classification__7QP58PHQC8__.09-53.32.hdf5
Epcoh: 8, Value: 0.481875

Epoch 00010: val_loss did not improve from 53.32041
Epcoh: 9, Value: 0.476875

Epoch 00011: val_loss did not improve from 53.32041
Epcoh: 10, Value: 0.44875

Epoch 00012: val_loss did not improve from 53.32041
Epcoh: 11, Value: 0.46875

Epoch 00013: val_loss did not improve from 53.32041
Epcoh: 12, Value: 0.47375

Epoch 00014: val_loss did not improve from 53.32041
Epcoh: 13, Value: 0.4825
end training
loaded from validating_generator
0.4825
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [2000, 1500, 1000],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 1500, 1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_70 (Dense)             (None, 2000)              1722000   
_________________________________________________________________
dense_71 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_72 (Dense)             (None, 1000)              1501000   
_________________________________________________________________
dense_73 (Dense)             (None, 1)                 1001      
=================================================================
Total params: 6,225,501
Trainable params: 6,225,501
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 860

Epoch 00001: val_loss improved from inf to 53.83277, saving model to ./tmp/classification__D53UX7SLYT__.01-53.83.hdf5
Epcoh: 0, Value: 0.4825

Epoch 00002: val_loss improved from 53.83277 to 53.58885, saving model to ./tmp/classification__D53UX7SLYT__.02-53.59.hdf5
Epcoh: 1, Value: 0.46375

Epoch 00003: val_loss did not improve from 53.58885
Epcoh: 2, Value: 0.469375

Epoch 00004: val_loss improved from 53.58885 to 53.28295, saving model to ./tmp/classification__D53UX7SLYT__.04-53.28.hdf5
Epcoh: 3, Value: 0.4825

Epoch 00005: val_loss did not improve from 53.28295
Epcoh: 4, Value: 0.479375

Epoch 00006: val_loss did not improve from 53.28295
Epcoh: 5, Value: 0.454375

Epoch 00007: val_loss did not improve from 53.28295
Epcoh: 6, Value: 0.44375

Epoch 00008: val_loss did not improve from 53.28295
Epcoh: 7, Value: 0.45125

Epoch 00009: val_loss did not improve from 53.28295
Epcoh: 8, Value: 0.434375
end training
loaded from validating_generator
0.4578125
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 1000],
 'loss_function': 'mean_squared_error',
 'optimizer': 'adam'}
TESTING
LAYERS: [2000, 1000]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_74 (Dense)             (None, 2000)              182000    
_________________________________________________________________
dense_75 (Dense)             (None, 1000)              2001000   
_________________________________________________________________
dense_76 (Dense)             (None, 2)                 2002      
=================================================================
Total params: 2,185,002
Trainable params: 2,185,002
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 90

Epoch 00001: val_loss improved from inf to 0.23306, saving model to ./tmp/classification__CSGP49AFLB__.01-0.23.hdf5
Epcoh: 0, Value: 0.60375

Epoch 00002: val_loss did not improve from 0.23306
Epcoh: 1, Value: 0.590625

Epoch 00003: val_loss did not improve from 0.23306
Epcoh: 2, Value: 0.611875

Epoch 00004: val_loss did not improve from 0.23306
Epcoh: 3, Value: 0.5925

Epoch 00005: val_loss did not improve from 0.23306
Epcoh: 4, Value: 0.589375

Epoch 00006: val_loss did not improve from 0.23306
Epcoh: 5, Value: 0.599375
end training
loaded from validating_generator
0.6125
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adagrad'}
TESTING
LAYERS: [200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_77 (Dense)             (None, 200)               172200    
_________________________________________________________________
dense_78 (Dense)             (None, 2)                 402       
=================================================================
Total params: 172,602
Trainable params: 172,602
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 860

Epoch 00001: val_loss improved from inf to 200932333.27703, saving model to ./tmp/classification__GZ6KTY5ZOJ__.01-200932333.28.hdf5
Epcoh: 0, Value: 0.57875

Epoch 00002: val_loss improved from 200932333.27703 to 199677727.76456, saving model to ./tmp/classification__GZ6KTY5ZOJ__.02-199677727.76.hdf5
Epcoh: 1, Value: 0.605

Epoch 00003: val_loss improved from 199677727.76456 to 199658558.06014, saving model to ./tmp/classification__GZ6KTY5ZOJ__.03-199658558.06.hdf5
Epcoh: 2, Value: 0.605

Epoch 00004: val_loss did not improve from 199658558.06014
Epcoh: 3, Value: 0.61

Epoch 00005: val_loss did not improve from 199658558.06014
Epcoh: 4, Value: 0.594375

Epoch 00006: val_loss did not improve from 199658558.06014
Epcoh: 5, Value: 0.5775

Epoch 00007: val_loss improved from 199658558.06014 to 198159887.71849, saving model to ./tmp/classification__GZ6KTY5ZOJ__.07-198159887.72.hdf5
Epcoh: 6, Value: 0.61

Epoch 00008: val_loss did not improve from 198159887.71849
Epcoh: 7, Value: 0.61625

Epoch 00009: val_loss did not improve from 198159887.71849
Epcoh: 8, Value: 0.613125

Epoch 00010: val_loss improved from 198159887.71849 to 197968103.14012, saving model to ./tmp/classification__GZ6KTY5ZOJ__.10-197968103.14.hdf5
Epcoh: 9, Value: 0.59375

Epoch 00011: val_loss did not improve from 197968103.14012
Epcoh: 10, Value: 0.61125

Epoch 00012: val_loss did not improve from 197968103.14012
Epcoh: 11, Value: 0.5875

Epoch 00013: val_loss did not improve from 197968103.14012
Epcoh: 12, Value: 0.605

Epoch 00014: val_loss did not improve from 197968103.14012
Epcoh: 13, Value: 0.575

Epoch 00015: val_loss did not improve from 197968103.14012
Epcoh: 14, Value: 0.59125
end training
loaded from validating_generator
0.605625
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [1000, 200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adamax'}
TESTING
LAYERS: [1000, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_79 (Dense)             (None, 1000)              121000    
_________________________________________________________________
dense_80 (Dense)             (None, 200)               200200    
_________________________________________________________________
dense_81 (Dense)             (None, 2)                 402       
=================================================================
Total params: 321,602
Trainable params: 321,602
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 120

Epoch 00001: val_loss improved from inf to 205898814.51056, saving model to ./tmp/classification__3M4N5LXBAB__.01-205898814.51.hdf5
Epcoh: 0, Value: 0.599375

Epoch 00002: val_loss did not improve from 205898814.51056
Epcoh: 1, Value: 0.571875

Epoch 00003: val_loss did not improve from 205898814.51056
Epcoh: 2, Value: 0.57375

Epoch 00004: val_loss did not improve from 205898814.51056
Epcoh: 3, Value: 0.5725

Epoch 00005: val_loss did not improve from 205898814.51056
Epcoh: 4, Value: 0.583125

Epoch 00006: val_loss improved from 205898814.51056 to 204669001.59693, saving model to ./tmp/classification__3M4N5LXBAB__.06-204669001.60.hdf5
Epcoh: 5, Value: 0.6

Epoch 00007: val_loss did not improve from 204669001.59693
Epcoh: 6, Value: 0.59125

Epoch 00008: val_loss did not improve from 204669001.59693
Epcoh: 7, Value: 0.58375

Epoch 00009: val_loss did not improve from 204669001.59693
Epcoh: 8, Value: 0.599375

Epoch 00010: val_loss did not improve from 204669001.59693
Epcoh: 9, Value: 0.58

Epoch 00011: val_loss did not improve from 204669001.59693
Epcoh: 10, Value: 0.578125
end training
loaded from validating_generator
0.5825
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 2,
 'layers': [1000, 200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [1000, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_82 (Dense)             (None, 1000)              1101000   
_________________________________________________________________
dense_83 (Dense)             (None, 200)               200200    
_________________________________________________________________
dense_84 (Dense)             (None, 2)                 402       
=================================================================
Total params: 1,301,602
Trainable params: 1,301,602
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 1100

Epoch 00001: val_loss improved from inf to 233885188.75496, saving model to ./tmp/classification__UF8UN8YN1R__.01-233885188.75.hdf5
Epcoh: 0, Value: 0.509375

Epoch 00002: val_loss improved from 233885188.75496 to 231565930.80486, saving model to ./tmp/classification__UF8UN8YN1R__.02-231565930.80.hdf5
Epcoh: 1, Value: 0.559375

Epoch 00003: val_loss did not improve from 231565930.80486
Epcoh: 2, Value: 0.526875

Epoch 00004: val_loss improved from 231565930.80486 to 230626231.34997, saving model to ./tmp/classification__UF8UN8YN1R__.04-230626231.35.hdf5
Epcoh: 3, Value: 0.51125

Epoch 00005: val_loss did not improve from 230626231.34997
Epcoh: 4, Value: 0.56

Epoch 00006: val_loss did not improve from 230626231.34997
Epcoh: 5, Value: 0.518125

Epoch 00007: val_loss did not improve from 230626231.34997
Epcoh: 6, Value: 0.515

Epoch 00008: val_loss did not improve from 230626231.34997
Epcoh: 7, Value: 0.535

Epoch 00009: val_loss did not improve from 230626231.34997
Epcoh: 8, Value: 0.531875
end training
loaded from validating_generator
0.534375
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [2000, 1500, 200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [2000, 1500, 200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_85 (Dense)             (None, 2000)              182000    
_________________________________________________________________
dense_86 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_87 (Dense)             (None, 200)               300200    
_________________________________________________________________
dense_88 (Dense)             (None, 1)                 201       
=================================================================
Total params: 3,483,901
Trainable params: 3,483,901
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 90

Epoch 00001: val_loss improved from inf to 52.99104, saving model to ./tmp/classification__6W7J3F7PM8__.01-52.99.hdf5
Epcoh: 0, Value: 0.4625

Epoch 00002: val_loss did not improve from 52.99104
Epcoh: 1, Value: 0.4675

Epoch 00003: val_loss did not improve from 52.99104
Epcoh: 2, Value: 0.470625

Epoch 00004: val_loss did not improve from 52.99104
Epcoh: 3, Value: 0.48625

Epoch 00005: val_loss did not improve from 52.99104
Epcoh: 4, Value: 0.47125

Epoch 00006: val_loss did not improve from 52.99104
Epcoh: 5, Value: 0.4625
end training
loaded from validating_generator
0.4671875
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': True,
 'label_classes': 1,
 'layers': [2000, 1500, 500],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adagrad'}
TESTING
LAYERS: [2000, 1500, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_89 (Dense)             (None, 2000)              662000    
_________________________________________________________________
dense_90 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_91 (Dense)             (None, 500)               750500    
_________________________________________________________________
dense_92 (Dense)             (None, 1)                 501       
=================================================================
Total params: 4,414,501
Trainable params: 4,414,501
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 330

Epoch 00001: val_loss improved from inf to 53.51687, saving model to ./tmp/classification__815J6DD2KX__.01-53.52.hdf5
Epcoh: 0, Value: 0.47625

Epoch 00002: val_loss did not improve from 53.51687
Epcoh: 1, Value: 0.473125

Epoch 00003: val_loss did not improve from 53.51687
Epcoh: 2, Value: 0.495625

Epoch 00004: val_loss did not improve from 53.51687
Epcoh: 3, Value: 0.464375

Epoch 00005: val_loss did not improve from 53.51687
Epcoh: 4, Value: 0.456875

Epoch 00006: val_loss improved from 53.51687 to 53.33293, saving model to ./tmp/classification__815J6DD2KX__.06-53.33.hdf5
Epcoh: 5, Value: 0.448125

Epoch 00007: val_loss did not improve from 53.33293
Epcoh: 6, Value: 0.454375

Epoch 00008: val_loss did not improve from 53.33293
Epcoh: 7, Value: 0.484375

Epoch 00009: val_loss did not improve from 53.33293
Epcoh: 8, Value: 0.4875

Epoch 00010: val_loss did not improve from 53.33293
Epcoh: 9, Value: 0.465625

Epoch 00011: val_loss did not improve from 53.33293
Epcoh: 10, Value: 0.480625
end training
loaded from validating_generator
0.4521875
{'epochs': 20,
 'final_activation_function': 'sigmoid',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 1,
 'layers': [2000, 1500, 500],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adamax'}
TESTING
LAYERS: [2000, 1500, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_93 (Dense)             (None, 2000)              1542000   
_________________________________________________________________
dense_94 (Dense)             (None, 1500)              3001500   
_________________________________________________________________
dense_95 (Dense)             (None, 500)               750500    
_________________________________________________________________
dense_96 (Dense)             (None, 1)                 501       
=================================================================
Total params: 5,294,501
Trainable params: 5,294,501
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 770

Epoch 00001: val_loss improved from inf to 52.94106, saving model to ./tmp/classification__R8JGP2YZJY__.01-52.94.hdf5
Epcoh: 0, Value: 0.461875

Epoch 00002: val_loss did not improve from 52.94106
Epcoh: 1, Value: 0.495625

Epoch 00003: val_loss did not improve from 52.94106
Epcoh: 2, Value: 0.469375

Epoch 00004: val_loss did not improve from 52.94106
Epcoh: 3, Value: 0.474375

Epoch 00005: val_loss improved from 52.94106 to 52.89907, saving model to ./tmp/classification__R8JGP2YZJY__.05-52.90.hdf5
Epcoh: 4, Value: 0.514375

Epoch 00006: val_loss did not improve from 52.89907
Epcoh: 5, Value: 0.475

Epoch 00007: val_loss did not improve from 52.89907
Epcoh: 6, Value: 0.455

Epoch 00008: val_loss improved from 52.89907 to 52.83509, saving model to ./tmp/classification__R8JGP2YZJY__.08-52.84.hdf5
Epcoh: 7, Value: 0.483125

Epoch 00009: val_loss did not improve from 52.83509
Epcoh: 8, Value: 0.4575

Epoch 00010: val_loss did not improve from 52.83509
Epcoh: 9, Value: 0.46875

Epoch 00011: val_loss did not improve from 52.83509
Epcoh: 10, Value: 0.4825

Epoch 00012: val_loss did not improve from 52.83509
Epcoh: 11, Value: 0.474375

Epoch 00013: val_loss did not improve from 52.83509
Epcoh: 12, Value: 0.4825
end training
loaded from validating_generator
0.4746875
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': False,
 'include_integrated_one_hot_encodings': True,
 'include_matchup_embeddings': True,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [200],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'adagrad'}
TESTING
LAYERS: [200]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_97 (Dense)             (None, 200)               42200     
_________________________________________________________________
dense_98 (Dense)             (None, 2)                 402       
=================================================================
Total params: 42,602
Trainable params: 42,602
Non-trainable params: 0
_________________________________________________________________
None
start training
Input Size: 210

Epoch 00001: val_loss improved from inf to 198655688.03071, saving model to ./tmp/classification__V68BWO573J__.01-198655688.03.hdf5
Epcoh: 0, Value: 0.606875

Epoch 00002: val_loss improved from 198655688.03071 to 198209327.10429, saving model to ./tmp/classification__V68BWO573J__.02-198209327.10.hdf5
Epcoh: 1, Value: 0.620625

Epoch 00003: val_loss did not improve from 198209327.10429
Epcoh: 2, Value: 0.6275

Epoch 00004: val_loss did not improve from 198209327.10429
Epcoh: 3, Value: 0.604375

Epoch 00005: val_loss did not improve from 198209327.10429
Epcoh: 4, Value: 0.611875

Epoch 00006: val_loss improved from 198209327.10429 to 197477876.64235, saving model to ./tmp/classification__V68BWO573J__.06-197477876.64.hdf5
Epcoh: 5, Value: 0.6075

Epoch 00007: val_loss improved from 197477876.64235 to 197180488.10749, saving model to ./tmp/classification__V68BWO573J__.07-197180488.11.hdf5
Epcoh: 6, Value: 0.603125

Epoch 00008: val_loss did not improve from 197180488.10749
Epcoh: 7, Value: 0.616875

Epoch 00009: val_loss did not improve from 197180488.10749
Epcoh: 8, Value: 0.6125

Epoch 00010: val_loss improved from 197180488.10749 to 196646936.61932, saving model to ./tmp/classification__V68BWO573J__.10-196646936.62.hdf5
Epcoh: 9, Value: 0.615625

Epoch 00011: val_loss improved from 196646936.61932 to 196584308.97505, saving model to ./tmp/classification__V68BWO573J__.11-196584308.98.hdf5
Epcoh: 10, Value: 0.596875

Epoch 00012: val_loss did not improve from 196584308.97505
Epcoh: 11, Value: 0.5975

Epoch 00013: val_loss did not improve from 196584308.97505
Epcoh: 12, Value: 0.60125

Epoch 00014: val_loss did not improve from 196584308.97505
Epcoh: 13, Value: 0.610625

Epoch 00015: val_loss did not improve from 196584308.97505
Epcoh: 14, Value: 0.5975

Epoch 00016: val_loss did not improve from 196584308.97505
Epcoh: 15, Value: 0.604375
end training
loaded from validating_generator
0.6015625
{'epochs': 20,
 'final_activation_function': 'softmax',
 'include_hero_embeddings': True,
 'include_integrated_one_hot_encodings': False,
 'include_matchup_embeddings': False,
 'include_seperate_one_hot_encodings': False,
 'label_classes': 2,
 'layers': [2000, 1500, 500],
 'loss_function': 'mean_absolute_percentage_error',
 'optimizer': 'nadam'}
TESTING
LAYERS: [2000, 1500, 500]
EPOCHS: 20
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_99 (Dense)             (None, 2000)              1542000   
_________________________________________________________________
dense_100 (Dense)            (None, 1500)              3001500   
_________________________________________________________________
dense_101 (Dense)            (None, 500)               750500    
_________________________________________________________________