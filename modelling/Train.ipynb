{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesaustin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6973861786534180462\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9777745101\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1954937066637595422\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hero_embeddings = json.load(open('normalized_embeddings.json', 'rb'))\n",
    "\n",
    "keys =  ['STR', 'STR+', 'STR25', 'AGI', 'AGI+', 'AGI25', 'INT', 'INT+', 'INT25', 'T', 'T+', 'T25', 'MS', 'AR', 'DMG(MIN)', 'DMG(MAX)', 'RG', 'BAT', 'ATK PT', 'ATK BS', 'VS-D', 'VS-N', 'TR', 'COL', 'HP/S', 'L', 'is_str', 'is_agi', 'is_int', '0_win', '0_gpm', '0_assists', '0_denies', '0_deaths', '0_kills', '0_last_hits', '0_level', '0_hero_damage', '0_hero_healing', '0_tower_damage', '0_xp_per_min', '1_win', '1_gpm', '1_assists', '1_denies', '1_deaths', '1_kills', '1_last_hits', '1_level', '1_hero_damage', '1_hero_healing', '1_tower_damage', '1_xp_per_min', '2_win', '2_gpm', '2_assists', '2_denies', '2_deaths', '2_kills', '2_last_hits', '2_level', '2_hero_damage', '2_hero_healing', '2_tower_damage', '2_xp_per_min', '3_win', '3_gpm', '3_assists', '3_denies', '3_deaths', '3_kills', '3_last_hits', '3_level', '3_hero_damage', '3_hero_healing', '3_tower_damage', '3_xp_per_min']\n",
    "\n",
    "def build_array_embedding(hero_embedding):\n",
    "    return [hero_embedding[key] for key in keys]\n",
    "\n",
    "array_hero_embeddings = {k: build_array_embedding(v) for k, v in hero_embeddings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendly_matchups = json.load(open('friendly_matchups.json', 'rb'))\n",
    "enemy_matchups = json.load(open('enemy_matchups.json', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['HERO', 'STR', 'STR+', 'STR25', 'AGI', 'AGI+', 'AGI25', 'INT', 'INT+', 'INT25', 'T', 'T+', 'T25', 'MS', 'AR', 'DMG(MIN)', 'DMG(MAX)', 'RG', 'BAT', 'ATK PT', 'ATK BS', 'VS-D', 'VS-N', 'TR', 'COL', 'HP/S', 'L', 'id', 'is_str', 'is_agi', 'is_int', '0_win', '0_gpm', '0_assists', '0_denies', '0_deaths', '0_kills', '0_last_hits', '0_level', '0_hero_damage', '0_hero_healing', '0_tower_damage', '0_xp_per_min', '1_win', '1_gpm', '1_assists', '1_denies', '1_deaths', '1_kills', '1_last_hits', '1_level', '1_hero_damage', '1_hero_healing', '1_tower_damage', '1_xp_per_min', '2_win', '2_gpm', '2_assists', '2_denies', '2_deaths', '2_kills', '2_last_hits', '2_level', '2_hero_damage', '2_hero_healing', '2_tower_damage', '2_xp_per_min', '3_win', '3_gpm', '3_assists', '3_denies', '3_deaths', '3_kills', '3_last_hits', '3_level', '3_hero_damage', '3_hero_healing', '3_tower_damage', '3_xp_per_min'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero_embeddings['86'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from toolbox.notebook import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from utils import *\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'data_generator', 'flatten', 'fs', 'get_files_in_folders', 'get_json_lines_in_folder', 'get_random_json_lines_from_files', 'get_transformed_lines', 'ignore_nones', 'itertools', 'json', 'lines_in_files', 'load_json_line', 'np', 'os', 'plt', 'progress_bar', 'randomized_buffer_generator', 'randrange', 'ready_image', 'show_image', 'shuffle']\n"
     ]
    }
   ],
   "source": [
    "import toolbox\n",
    "print(dir(toolbox.notebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(get_files_in_folders('./scraper/scrape_results/')[0], 'rb') as file_refs:\n",
    "    lines = [x for x in file_refs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_embedding_from_match(player, match, radient):\n",
    "    def get_player_matchup(other_player):\n",
    "        hostile = other_player['player_slot'] > 127 and radient\n",
    "        relevant_matchup = enemy_matchups if hostile else friendly_matchups  \n",
    "        try:\n",
    "            return relevant_matchup[player['hero_id']][other_player['hero_id']]\n",
    "        except KeyError:\n",
    "            import pdb; pdb.set_trace()\n",
    "            pass\n",
    "    return [get_player_matchup(other_player) for other_player in match['players']\n",
    "            if player != other_player]\n",
    "\n",
    "def get_team_one_hot_encodings(players, total_size=120):\n",
    "    encoding = np.zeros(120)\n",
    "    for player in players:\n",
    "        encoding[int(player['hero_id']) -1] = 1\n",
    "    return encoding\n",
    "\n",
    "def transform_match(match):\n",
    "    if proper_match(match) is False:\n",
    "        return None\n",
    "    for player in match['players']:\n",
    "        player['hero_id'] = str(player['hero_id'])\n",
    "    radient = match['players'][0:5]\n",
    "    dire = match['players'][5:]\n",
    "    \n",
    "    radient = sorted(radient, key=lambda x: int(x['hero_id']))\n",
    "    dire = sorted(dire, key=lambda x: int(x['hero_id']))\n",
    "#     random.shuffle(radient)\n",
    "#     random.shuffle(dire)\n",
    "    \n",
    "    radient_matchups_embeddings = [get_player_embedding_from_match(player, match, True) for player in radient]\n",
    "    dire_matchups_embeddings = [get_player_embedding_from_match(player, match, False) for player in dire]\n",
    "    hero_embeddings = [array_hero_embeddings[x['hero_id']] for x in radient+dire]\n",
    "    \n",
    "    embeddings = flatten(radient_matchups_embeddings + dire_matchups_embeddings + hero_embeddings)\n",
    "    embeddings.extend(get_team_one_hot_encodings(radient))\n",
    "    embeddings.extend(get_team_one_hot_encodings(dire))\n",
    "    \n",
    "    label = [1,0] if match['radiant_win'] else [0,1]\n",
    "    \n",
    "    return embeddings, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesaustin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def data_generator(filepaths, batch_size=32):\n",
    "    #loading data\n",
    "    batch_events = []\n",
    "    batch_labels = []\n",
    "    while True:\n",
    "        for match, label in get_random_json_lines_from_files(filepaths, \n",
    "                                                             transform_func=transform_match):\n",
    "            if len(batch_events) == batch_size:\n",
    "                yield np.array(batch_events), np.array(batch_labels)\n",
    "                batch_events = []\n",
    "                batch_labels = []\n",
    "            batch_events.append(match)\n",
    "            batch_labels.append(label)\n",
    "#         print(\"Full touch\")\n",
    "#         random.shuffle(filepaths)\n",
    "#         for filepath in progress_bar(filepaths):\n",
    "#             with open(filepath, 'rb') as file_refs:\n",
    "#                 lines = [load_line(x) for x in file_refs]\n",
    "#                 lines = [x for x in lines if x]\n",
    "#                 random.shuffle(lines)\n",
    "#                 for line in lines:\n",
    "#                     if len(batch_events) == batch_size:\n",
    "#                  /       yield np.array(batch_events), np.array(batch_labels)\n",
    "#                         batch_events = []\n",
    "#                         batch_labels = []\n",
    "#                     match, label = transform_match(line)\n",
    "#                     batch_events.append(match)\n",
    "#                     batch_labels.append(label)\n",
    "          \n",
    "all_files = get_files_in_folders('./scraper/scrape_results/')\n",
    "\n",
    "training_set, validating_set = train_test_split(all_files, train_size=0.9)\n",
    "    \n",
    "training_generator = data_generator(training_set, batch_size=batch_size)\n",
    "validating_generator = data_generator(validating_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Output Shape\n",
    "\n",
    "hero_embeddings_count = 10 * len(keys) #10 characters, each with a set number of keys from the hero embeddings\n",
    "matchup_embeddings_count = 10 * 9 # 10 people, with matchup numbers for every other player\n",
    "one_hot_embeddings = 120 * 2 # Hero count * team count\n",
    "total_input_number = hero_embeddings_count + matchup_embeddings_count + one_hot_embeddings\n",
    "\n",
    "generator_value = training_generator.__next__()[0][0] # Skip first axis (value/label) and second axis (batch)\n",
    "print(f\"Actual: {len(generator_value)}\")\n",
    "print(f\"Expected: {total_input_number}\")\n",
    "\n",
    "assert(len(generator_value) == total_input_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(800, input_shape=(total_input_number,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(300))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"./tmp/classification_2_.{epoch:02d}-{val_loss:.2f}.hdf5\", verbose=1)\n",
    "\n",
    "# model.fit_generator(training_generator, \n",
    "#                     steps_per_epoch=1350000/batch_size, \n",
    "#                     epochs=20, \n",
    "#                     verbose=0,\n",
    "#                     validation_data=validating_generator, \n",
    "#                     validation_steps=150000/(batch_size/2), \n",
    "#                     callbacks=[checkpointer,TQDMNotebookCallback()])\n",
    "\n",
    "model.fit_generator(training_generator, \n",
    "                    steps_per_epoch=int(500000/batch_size),#1350000/batch_size/100, \n",
    "                    epochs=1000, \n",
    "                    verbose=0,\n",
    "                    validation_data=validating_generator, \n",
    "                    validation_steps=10, #/(batch_size/2)/100, \n",
    "                    callbacks=[checkpointer,TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = []\n",
    "test_labels = []\n",
    "for x in range(0, 100):\n",
    "    test_value, label = validating_generator.__next__()\n",
    "    test_values.extend(test_value)\n",
    "    test_labels.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in get_files_in_folders\n",
    "\n",
    "num_correct = 0\n",
    "for value, label in zip(test_values, test_labels):\n",
    "    evalled_result = model.predict(np.array((value,)))\n",
    "    prediction = evalled_result[0][0] > evalled_result[0][1]\n",
    "    correct = prediction == label[0]\n",
    "    print(f\"{evalled_result} == {label} - {correct}\")\n",
    "    if correct:\n",
    "        num_correct += 1\n",
    "print(num_correct/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/classification_2_.07-0.68.hdf5\n",
      "0.5540625\n",
      "./tmp/classification_2_.54-0.69.hdf5\n",
      "0.5884375\n",
      "./tmp/classification_1_.05-0.67.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.50-0.68.hdf5\n",
      "0.59125\n",
      "./tmp/classification_2_.02-0.66.hdf5\n",
      "0.561875\n",
      "./tmp/classification_2_.44-0.71.hdf5\n",
      "0.5790625\n",
      "./tmp/classification_2_.03-0.68.hdf5\n",
      "0.5625\n",
      "./tmp/classification_2_.12-0.69.hdf5\n",
      "0.5725\n",
      "./tmp/classification_2_.24-0.68.hdf5\n",
      "0.5696875\n",
      "./tmp/classification_2_.26-0.69.hdf5\n",
      "0.5609375\n",
      "./tmp/classification_1_.09-0.66.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.09-0.70.hdf5\n",
      "0.575\n",
      "./tmp/classification_2_.27-0.69.hdf5\n",
      "0.59875\n",
      "./tmp/classification_2_.20-0.70.hdf5\n",
      "0.5571875\n",
      "./tmp/classification_2_.56-0.64.hdf5\n",
      "0.6034375\n",
      "./tmp/classification_1_.08-0.68.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.01-0.70.hdf5\n",
      "Error when checking : expected dense_16_input to have shape (860,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.18-0.66.hdf5\n",
      "0.590625\n",
      "./tmp/classification_2_.22-0.68.hdf5\n",
      "0.56875\n",
      "./tmp/classification_2_.01-0.65.hdf5\n",
      "Error when checking : expected dense_21_input to have shape (860,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.17-0.69.hdf5\n",
      "0.6025\n",
      "./tmp/classification_1_.12-0.67.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_1_.13-0.68.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.23-0.68.hdf5\n",
      "0.5578125\n",
      "./tmp/classification_2_.48-0.66.hdf5\n",
      "0.6003125\n",
      "./tmp/classification_2_.38-0.65.hdf5\n",
      "0.591875\n",
      "./tmp/classification_1_.14-0.68.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.49-0.66.hdf5\n",
      "0.6025\n",
      "./tmp/classification_1_.02-0.67.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (860,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.21-0.69.hdf5\n",
      "0.5921875\n",
      "./tmp/classification_2_.59-0.67.hdf5\n",
      "0.555\n",
      "./tmp/classification_2_.45-0.65.hdf5\n",
      "0.5975\n",
      "./tmp/classification_2_.35-0.71.hdf5\n",
      "0.579375\n",
      "./tmp/classification_2_.52-0.68.hdf5\n",
      "0.6053125\n",
      "./tmp/classification_2_.05-0.69.hdf5\n",
      "0.58875\n",
      "./tmp/classification_2_.01-0.68.hdf5\n",
      "0.556875\n",
      "./tmp/classification_1_.01-0.68.hdf5\n",
      "Error when checking : expected dense_31_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_1_.02-0.66.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.16-0.64.hdf5\n",
      "0.5803125\n",
      "./tmp/classification_2_.08-0.70.hdf5\n",
      "0.5659375\n",
      "./tmp/classification_2_.25-0.70.hdf5\n",
      "0.554375\n",
      "./tmp/classification_2_.10-0.74.hdf5\n",
      "0.5865625\n",
      "./tmp/classification_2_.43-0.70.hdf5\n",
      "0.596875\n",
      "./tmp/classification_2_.15-0.73.hdf5\n",
      "0.5315625\n",
      "./tmp/classification_1_.04-0.66.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.19-0.68.hdf5\n",
      "0.589375\n",
      "./tmp/classification_2_.31-0.74.hdf5\n",
      "0.5678125\n",
      "./tmp/classification_2_.05-0.66.hdf5\n",
      "0.5771875\n",
      "./tmp/classification_2_.29-0.69.hdf5\n",
      "0.560625\n",
      "./tmp/classification_2_.41-0.70.hdf5\n",
      "0.568125\n",
      "./tmp/classification_2_.46-0.66.hdf5\n",
      "0.5740625\n",
      "./tmp/classification_1_.06-0.70.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.55-0.66.hdf5\n",
      "0.604375\n",
      "./tmp/classification_2_.03-0.69.hdf5\n",
      "0.5953125\n",
      "./tmp/classification_2_.40-0.66.hdf5\n",
      "0.5909375\n",
      "./tmp/classification_2_.02-0.67.hdf5\n",
      "Error when checking : expected dense_21_input to have shape (860,) but got array with shape (1100,)\n",
      "./tmp/classification_1_.11-0.68.hdf5\n",
      "Error when checking : expected dense_1_input to have shape (770,) but got array with shape (1100,)\n",
      "./tmp/classification_2_.36-0.66.hdf5\n",
      "0.5778125\n",
      "./tmp/classification_2_.47-0.66.hdf5\n",
      "0.5765625\n",
      "./tmp/classification_2_.14-0.66.hdf5\n",
      "0.568125\n",
      "./tmp/classification_2_.57-0.66.hdf5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for file_path in get_files_in_folders('./tmp/'):\n",
    "    model = keras.models.load_model(file_path)\n",
    "    print(file_path)\n",
    "    num_correct = 0\n",
    "    try:\n",
    "        for value, label in zip(test_values, test_labels):\n",
    "            evalled_result = model.predict(np.array((value,)))\n",
    "            prediction = evalled_result[0][0] > evalled_result[0][1]\n",
    "            correct = prediction == label[0]\n",
    "            #print(f\"{evalled_result} == {label} - {correct}\")\n",
    "            if correct:\n",
    "                num_correct += 1\n",
    "        print(num_correct/len(test_labels))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
